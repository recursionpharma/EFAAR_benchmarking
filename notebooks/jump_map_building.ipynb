{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Benchmarking a Biological Map with JUMP-Cell Painting Consortium Cell Profiler Features\n",
    "\n",
    "In this notebook, we create and benchmark maps based on the JUMP-CP imaging dataset featurized with Cell Profiler. The focus will be on creating simple EFAAR pipelines and benchmarking using the framework to see how changes in the pipeline effect the metrics.\n",
    "\n",
    "The primary components of an EFAAR Pipeline are \n",
    "\n",
    "- **Embeddings:** A high dimensional featurization of a biological perturbation\n",
    "- **Filter:** A preprocessing step where embeddings are discarded based on statistical, machine learning thresholds or external metadata or features \n",
    "- **Align:** Process to combine the embeddings into the same high dimensional space while increasing the the signal and decreasing noise in the data \n",
    "- **Aggregate:** Combining any replicates of perturbations into a single representation for comparison \n",
    "- **Relation:** Any metric that allows pairwise comparison between perturbations\n",
    "\n",
    "Additionally, we will examine the presence of chromosomal proximity bias in the data and alter the pipeline to decrease its effect on relationships. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "import scipy.spatial.distance as scipy_distance\n",
    "from scipy.spatial.distance import pdist\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.utils import Bunch\n",
    "import scipy.linalg as linalg\n",
    "\n",
    "from efaar_benchmarking.benchmarking import benchmark as bm\n",
    "from efaar_benchmarking.utils import get_benchmark_metrics\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "Load the cpg0016 CRISPR data. The metadata is not available via an API so it has been copied from the Cell Painting gallery for ease of use. But the features can be easily pulled from the S3 bucket provided by the JUMP consortium. We pickle the raw data after loading to avoid repeatedly pulling from the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FEATURE_FORMATTER = (\n",
    "    \"s3://cellpainting-gallery/cpg0016-jump/\"\n",
    "    \"{Metadata_Source}/workspace/profiles/\"\n",
    "    \"{Metadata_Batch}/{Metadata_Plate}/{Metadata_Plate}.parquet\"\n",
    ")\n",
    "\n",
    "CPG_METADATA_COLS = [\n",
    "    \"Metadata_Source\",\n",
    "    \"Metadata_Plate\",\n",
    "    \"Metadata_Well\",\n",
    "    \"Metadata_JCP2022\",\n",
    "    \"Metadata_Batch\",\n",
    "    \"Metadata_PlateType\",\n",
    "    \"Metadata_NCBI_Gene_ID\",\n",
    "    \"Metadata_Symbol\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_cpg_crispr_well_metadata():\n",
    "    \"\"\"Load well metadata for CRISPR plates from Cell Painting Gallery.\"\"\"\n",
    "    plates = pd.read_csv(\"data/plate.csv.gz\")\n",
    "    crispr_plates = plates.query(\"Metadata_PlateType=='CRISPR'\")\n",
    "    wells = pd.read_csv(\"data/well.csv.gz\")\n",
    "    crispr = pd.read_csv(\"data/crispr.csv.gz\")\n",
    "\n",
    "    well_plate = wells.merge(crispr_plates, on=[\"Metadata_Source\", \"Metadata_Plate\"])\n",
    "    crispr_well_metadata = well_plate.merge(crispr, on=\"Metadata_JCP2022\")\n",
    "    return crispr_well_metadata\n",
    "\n",
    "\n",
    "def _load_plate_features(path: str):\n",
    "    try:\n",
    "        df = pd.read_parquet(\"data/\" + path.split(\"/\")[-1])\n",
    "    except FileNotFoundError:\n",
    "        df = pd.read_parquet(path, storage_options={\"anon\": True})\n",
    "        df.to_parquet(\"data/\" + path.split(\"/\")[-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_feature_data(metadata_df: pd.DataFrame, max_workers=4) -> pd.DataFrame:\n",
    "    \"\"\"Load feature data from Cell Painting Gallery from metadata dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata_df : pd.DataFrame\n",
    "        Well metadata dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Well features\n",
    "    \"\"\"\n",
    "    cripsr_plates = metadata_df[\n",
    "        [\"Metadata_Source\", \"Metadata_Batch\", \"Metadata_Plate\", \"Metadata_PlateType\"]\n",
    "    ].drop_duplicates()\n",
    "    data = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executer:\n",
    "        future_to_plate = {\n",
    "            executer.submit(\n",
    "                _load_plate_features, CP_FEATURE_FORMATTER.format(**row.to_dict())\n",
    "            ): CP_FEATURE_FORMATTER.format(**row.to_dict())\n",
    "            for _, row in cripsr_plates.iterrows()\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_plate):\n",
    "            data.append(future.result())\n",
    "    return pd.concat(data)\n",
    "\n",
    "\n",
    "def build_combined_data(metadata: pd.DataFrame, features: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Join well metadata and well features\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata : pd.DataFrame\n",
    "        Well metadata\n",
    "    features : pd.DataFrame\n",
    "        Well features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Combined dataframe\n",
    "    \"\"\"\n",
    "    return metadata.merge(features, on=[\"Metadata_Source\", \"Metadata_Plate\", \"Metadata_Well\"])\n",
    "\n",
    "\n",
    "def read_parquets_from_gcs():\n",
    "    data = []\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            data.append(pd.read_parquet(f\"data/cpg_0016_crispr_{i}.parquet\"))\n",
    "        except FileNotFoundError:\n",
    "            subset = pd.read_parquet(f\"gs://rxrx-cytodata2023-public/cpg_0016_crispr_{i}.parquet\")\n",
    "            subset.to_parquet(f\"data/cpg_0016_crispr_{i}.parquet\")\n",
    "            data.append(subset)\n",
    "        print(f\"Read in parquet {i+1} of 10\")\n",
    "    return pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_well_data = read_parquets_from_gcs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and benchmarking an initial map\n",
    "Let's create and benchmark an initial map with a simple EFAAR pipeline to serve as a baseline\n",
    "\n",
    "- **Embeddings:** Cell Profiler Embeddings from JUMP cpg0016\n",
    "- **Filter:** Filtering out rows with Nan values\n",
    "- **Align:** Centering and scaling the individual features followed by PCA keeping a fraction of the variance \n",
    "- **Aggregate:** The mean over the well replicates of each gene KO\n",
    "- **Relation:** Cosine similarity between the perturbations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    data: pd.DataFrame, metadata_cols: list = CPG_METADATA_COLS, drop_image_cols: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Preprocess data by dropping feature columns with nan values,\n",
    "    and optionaly dropping the Image columns\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data to preprocess\n",
    "    metadata_cols : List[str], optional\n",
    "        Metadata columns, by default CPG_METADATA_COLS\n",
    "    drop_image_cols : bool, optional\n",
    "        Whether to drop Image columns, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe\n",
    "    \"\"\"\n",
    "    metadata = data[metadata_cols]\n",
    "    features = data[[col for col in data.columns if col not in metadata_cols]]\n",
    "    features = features.dropna(axis=1)\n",
    "    if drop_image_cols:\n",
    "        image_cols = [col for col in features.columns if col.startswith(\"Image_\")]\n",
    "        features = features.drop(columns=image_cols)\n",
    "    return metadata.join(features)\n",
    "\n",
    "\n",
    "def pca_transform_data(data, \n",
    "    metadata_cols: list = CPG_METADATA_COLS,\n",
    "    variance=0.98,\n",
    "    pca_fit_fraction = 1.0,) -> pd.DataFrame:\n",
    "    \"\"\"Align data by centerscaling data and then transforming by PCA\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data to preprocess\n",
    "    metadata_cols : List[str], optional\n",
    "        Metadata columns, by default CPG_METADATA_COLS\n",
    "    pca_fit_fraction : bool, optional\n",
    "        Fraction of wells to sample for PCA, by default 1.0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = data[metadata_cols]\n",
    "    features = data[[col for col in data.columns if col not in metadata_cols]]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features.loc[:,:] = scaler.fit_transform(\n",
    "        features\n",
    "    )\n",
    "    \n",
    "    pca = PCA(variance)\n",
    "    pca.fit(features.sample(frac=pca_fit_fraction, random_state=42))\n",
    "    features = pd.DataFrame(pca.transform(features), index=metadata.index)\n",
    "\n",
    "    return metadata.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_well_data = pca_transform_data(preprocess_data(raw_well_data), pca_fit_fraction=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = transformed_well_data[[col for col in transformed_well_data.columns if col not in CPG_METADATA_COLS]]\n",
    "aggregated_data = features.groupby(transformed_well_data[\"Metadata_Symbol\"], as_index=True).mean()\n",
    "aggregated_data.index.name = \"gene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships\n",
    "Visualizing relationships of some well known gene sets that we expect to cluster together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairwise_cos(\n",
    "    df: pd.DataFrame,\n",
    "    convert: bool = True,\n",
    "    dtype: type = np.float16,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a dataframe of samples X features into a square dataframe of samples X samples\n",
    "    of cosine similarities between rows.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    - df = pd.DataFrame\n",
    "    - convert = bool. Whether to convert the results to a smaller data type\n",
    "    - dtype = type. Data type to convert to\n",
    "    \"\"\"\n",
    "    mat = (1 - sp.spatial.distance.cdist(df.values, df.values, metric=\"cosine\")).clip(-1, 1)\n",
    "    if convert:\n",
    "        mat = mat.astype(dtype)\n",
    "    return pd.DataFrame(mat, index=df.index, columns=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_perturbations(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes a square data frame, and uses euclidian distance to reorder the rows and columns\n",
    "    into clusters. The index and column values for the data frame must be identical to eachother.\n",
    "    \"\"\"\n",
    "    if list(data.index) != list(data.columns):\n",
    "        raise ValueError(\"index and columns for pldata must be equal\")\n",
    "\n",
    "    order = hierarchy.dendrogram(\n",
    "            hierarchy.linkage(\n",
    "                pdist(data)\n",
    "            ),\n",
    "            no_plot=True,\n",
    "        )['ivl']\n",
    "    data = data.iloc[order]\n",
    "    data = data[data.index]\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_cosine_rectangle_data(pldata: pd.DataFrame, title: str='plot', h=600, w=600):\n",
    "    \"\"\"\n",
    "    pldata is expected to be a rectangular dataframe, where all the values are to be plotted\n",
    "    \"\"\"\n",
    "    pldata = cluster_perturbations(data=pldata)\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=pldata.values,\n",
    "        x=pldata.columns,\n",
    "        y=pldata.index,\n",
    "        colorscale='RdBu_r',\n",
    "        zmin=-1,\n",
    "        zmax=1,\n",
    "    ))\n",
    "    fig.update_layout(height=h, width=w, title_text=f\"{title}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sets = {\n",
    "    'PROTEASOME': 'PSMB2,PSMB7,PSMB4,PSMA7,PSMA4,PSMB6,PSMA5,PSMB3,PSMA6,PSMA1,PSMB1,PSMA3'.split(','),\n",
    "    'EXOSOME': 'DIS3,EXOSC4,EXOSC8,EXOSC7,EXOSC9,EXOSC5'.split(','),\n",
    "    'VATPASE': 'ATP6V1B2,ATP6V1H,ATP6V1D,ATP6V1A,ATP6V1F,ATP6V1E1'.split(','),\n",
    "    'AUTOPHAGY': 'ATG12,ATG5'.split(','),\n",
    "    'REPLICATION_FACTOR_COMPLEX': 'RFC3,RFC4,RFC2,RFC5'.split(','),  \n",
    "    'DYNEIN': 'DYNC1I2,DYNC1H1,DYNC1LI1,DYNC1LI2'.split(','),\n",
    "    'RNA': 'POLA2,POLA1,POLR2L,POLR2B,POLR2I,POLR2G,POLR2C'.split(','), \n",
    "    'EGFR': 'PRKCE,BRAF,HRAS,SHC1,RAF1,EGFR,MAPK1'.split(','),\n",
    "    'TGFB/ACTIVIN': 'ACVR1B,TGFBR2,TGFBR1'.split(','),\n",
    "    }\n",
    "\n",
    "cluster_genes = [g for gene_set in gene_sets.values() for g in gene_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cosine_rectangle_data(make_pairwise_cos(aggregated_data.loc[cluster_genes]), title = \"JUMP Gene Sets - Initial EFAAR Pipeline\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "Plots provide a nice visualization but we can quantify how well the map is recapitulating biology with these metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Benchmarks\n",
    "The multivariate benchmarks compare annotated sets of known relationships against a distribution of randomly selected embeddings and computes recall based on the percentiles of the random distribution. In this notebook we will use the 5th and 95th percentil. Hence, embeddings that don't have biological signal are expected to have around "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = aggregated_data.reset_index()[['gene']]\n",
    "features = aggregated_data.reset_index(drop=True)\n",
    "results_dict = bm(Bunch(metadata=metadata, features=features), pert_label_col='gene', run_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_results_df = get_benchmark_metrics(results_dict)\n",
    "benchmark_results_df['map_version'] = 'JUMP_initial_EFAAR'\n",
    "sns.barplot(data=benchmark_results_df, x='source' ,y='recall')\n",
    "plt.axhline(y=0.1, color='red', linestyle='--') \n",
    "plt.title('Recall at 5th and 95th Percentiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Benchmarks\n",
    "For the univariate benchmarks we can compare a metric that measures the consistency of the well level replicates of a perturbation against an empirical null where the metrics is computed on random sets of replicates. This computation can be very sensative to the null distribution. Incorporating the experiment design in the null is import but can become computationally expensive very quickly. The following is an example of the idea but a production implementation needs more refinement and comptue. We are not matching plates or well address for example which can make replicates look more similar to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_angle(df):\n",
    "    cosine_sim = sklearn.metrics.pairwise.cosine_similarity(df.values)\n",
    "    if cosine_sim.shape[0]==1:\n",
    "        print(\"Whatt???\")\n",
    "    return np.arccos(cosine_sim[np.tril_indices(cosine_sim.shape[0], k=-1)]).mean()\n",
    "\n",
    "def generate_null_distribution(feature_data, n_samples = 10000, cardinality = 5):\n",
    "    \"\"\"Generate null distribution for univariate avg cosine sim metric\"\"\"\n",
    "    null_metrics = []\n",
    "    for i in range(n_samples):\n",
    "        null_metrics.append(avg_angle(feature_data.sample(n=cardinality)))\n",
    "    return null_metrics\n",
    "\n",
    "\n",
    "def compute_cosine_sim_metric2(data: pd.DataFrame, metadata_cols=CPG_METADATA_COLS, cardinality=5):\n",
    "    \"\"\"Compute univariate cosine similarity metrics on well level data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data to process\n",
    "    metadata_cols : List[str], optional\n",
    "        Metadata columns, by default CPG_METADATA_COLS\n",
    "    cardinality : bool, optional\n",
    "        Cardinatity of the wells to match when generating the null distribution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe\n",
    "    \"\"\"\n",
    "    data = data.query('Metadata_Symbol != \"no-guide\" and Metadata_Symbol != \"non-targeting\" and Metadata_Symbol != \"PLK1\"')\n",
    "    gene_count = data.groupby('Metadata_Symbol').Metadata_Well.count()\n",
    "    genes = list(gene_count[gene_count==5].index)\n",
    "    data = data.query('Metadata_Symbol.isin(@genes)')\n",
    "    \n",
    "    perts = data[['Metadata_Symbol']]\n",
    "    features = data[[col for col in data.columns if col not in metadata_cols]]\n",
    "\n",
    "    df = perts.join(features)\n",
    "    query_metrics = df.drop(columns = \"Metadata_Symbol\").groupby(df['Metadata_Symbol']).apply(avg_angle)\n",
    "    query_metrics.name = \"avg_cossim\"\n",
    "    query_metrics = query_metrics.reset_index()\n",
    "\n",
    "    null = []\n",
    "    for i in range(5):\n",
    "        df['Metadata_Symbol'] = df['Metadata_Symbol'].sample(frac=1).values\n",
    "        null.extend(df.drop(columns = \"Metadata_Symbol\").groupby(df['Metadata_Symbol']).apply(avg_angle).values)\n",
    "    sorted_null = np.sort(null)\n",
    "    query_metrics['avg_cossim_pval'] = np.searchsorted(sorted_null, query_metrics.avg_cossim)/len(sorted_null)\n",
    "    return query_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_univariate_metrics = compute_cosine_sim_metric2(transformed_well_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num01genes = len(initial_univariate_metrics.query(\"avg_cossim_pval<=0.01\"))\n",
    "num05genes = len(initial_univariate_metrics.query(\"avg_cossim_pval<=0.05\"))\n",
    "print(f\"{num01genes} significant genes at a 0.01 significance threshold\")\n",
    "print(f\"{num05genes} significant genes at a 0.05 significance threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Map\n",
    "Let's iterate on the EFAAR pipeline to try to improve our both the univariate and multivariate benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = raw_well_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in cols if \"ImageQuality_MeanIntensity\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in cols if \"Object_Number\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_well_data['Image_ImageQuality_MeanIntensity_OrigDNA'].plot(kind='kde')\n",
    "plt.title('Mean Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_well_data['Cytoplasm_Number_Object_Number'].plot(kind='kde')\n",
    "plt.title('Object Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_image_intensity(df,contamination=0.01):\n",
    "    \"\"\"Filter dataframe by image intensity threshold.\"\"\"\n",
    "\n",
    "    intensity_cols = [col for col in cols if \"ImageQuality_MeanIntensity\" in col]\n",
    "    image_data = df[intensity_cols]\n",
    "    envelope = EllipticEnvelope(contamination=contamination, random_state=42)\n",
    "    lables = envelope.fit_predict(image_data)\n",
    "    return df.loc[lables == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_cell_count(df, threshold):\n",
    "    \"\"\"Filter dataframe by cell count\"\"\"\n",
    "    mask = (df['Cytoplasm_Number_Object_Number'] >= threshold) & (df['Nuclei_Number_Object_Number'] >= threshold)\n",
    "    return df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_preprocess_data(\n",
    "    data: pd.DataFrame, metadata_cols: list = CPG_METADATA_COLS, drop_image_cols: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Preprocess data by dropping feature columns with nan values, dropping the\n",
    "    Number_Object columns, and optionaly dropping the Image columns\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data to preprocess\n",
    "    metadata_cols : List[str], optional\n",
    "        Metadata columns, by default CPG_METADATA_COLS\n",
    "    drop_image_cols : bool, optional\n",
    "        Whether to drop Image columns, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Processed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = data[metadata_cols]\n",
    "    features = data[[col for col in data.columns if col not in metadata_cols]]\n",
    "    features = features.dropna(axis=1)\n",
    "    data = metadata.join(features)\n",
    "    data = filter_by_image_intensity(data)\n",
    "    data = filter_by_cell_count(data, threshold=20)    \n",
    "\n",
    "    data = data.drop(columns=[col for col in data.columns if col.endswith(\"Object_Number\")])\n",
    "\n",
    "    if drop_image_cols:\n",
    "        image_cols = [col for col in data.columns if col.startswith(\"Image_\")]\n",
    "        data = data.drop(columns=image_cols)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing on the raw data\n",
    "print(len(raw_well_data), \"wells before filtering\")\n",
    "processed_data = filter_and_preprocess_data(raw_well_data)\n",
    "print(len(processed_data), \"wells after filterng\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_modified_cov(data: pd.DataFrame):\n",
    "        return np.cov(data, rowvar=False, ddof=1) + 0.5 * np.eye(\n",
    "            np.shape(data)[1], dtype=np.float32\n",
    "        )\n",
    "\n",
    "\n",
    "def tvn_transform(\n",
    "    data: pd.DataFrame,\n",
    "    metadata_cols: list = CPG_METADATA_COLS,\n",
    "    variance=0.98,\n",
    "    pca_fit_fraction = .1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Transform data by scaling and applying PCA. Data is scaled by plate\n",
    "    before and after PCA is applied. The experimental replicates are averaged\n",
    "    together by taking the mean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data to transform\n",
    "    metadata_cols : list, optional\n",
    "        Metadata columns, by default CPG_METADATA_COLS\n",
    "    variance : float, optional\n",
    "        Variance to keep after PCA, by default 0.98\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transformed data\n",
    "    \"\"\"\n",
    "    metadata = data[metadata_cols]\n",
    "    features = data[[col for col in data.columns if col not in metadata_cols]]\n",
    "\n",
    "    for plate in metadata.Metadata_Plate.unique():\n",
    "        scaler = StandardScaler()\n",
    "        features.loc[metadata.Metadata_Plate == plate, :] = scaler.fit_transform(\n",
    "            features.loc[metadata.Metadata_Plate == plate, :]\n",
    "        )\n",
    "\n",
    "    pca = PCA(variance)\n",
    "    pca.fit(features.sample(frac=pca_fit_fraction, random_state=42))\n",
    "    features = pd.DataFrame(pca.transform(features), index= metadata.index)\n",
    "\n",
    "    for plate in metadata.Metadata_Plate.unique():\n",
    "        scaler = StandardScaler()\n",
    "        features.loc[metadata.Metadata_Plate == plate, :] = scaler.fit_transform(\n",
    "            features.loc[metadata.Metadata_Plate == plate, :]\n",
    "        )\n",
    "\n",
    "    for batch in metadata.Metadata_Batch.unique():\n",
    "        source_cov = _compute_modified_cov(features.loc[metadata.query(f\"Metadata_Batch == '{batch}'\").index])\n",
    "        source_cov_half_inv = linalg.fractional_matrix_power(source_cov, -0.5)\n",
    "                                 \n",
    "        features.loc[metadata.Metadata_Batch == batch, :] = np.matmul(\n",
    "            features.loc[metadata.Metadata_Batch == batch, :],\n",
    "            source_cov_half_inv,\n",
    "        )                                   \n",
    "    return metadata.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run alignment on the processed data\n",
    "# This takes a while, so we only use a fraction of the data to fit the PCA\n",
    "tvn_transformed_well_data = tvn_transform(processed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tvn_transformed_well_data[[col for col in tvn_transformed_well_data.columns if col not in CPG_METADATA_COLS]]\n",
    "aggregated_tvn_data = features.groupby(tvn_transformed_well_data[\"Metadata_Symbol\"], as_index=True).median()\n",
    "aggregated_tvn_data.index.name = \"gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "aggregated_tvn_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cosine_rectangle_data(make_pairwise_cos(aggregated_tvn_data.loc[cluster_genes]), title = \"JUMP Gene Sets - Improved EFAAR Pipeline\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multivariate Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = aggregated_tvn_data.reset_index()[['gene']]\n",
    "features = aggregated_tvn_data.reset_index(drop=True)\n",
    "data_dict['improved_EFAAR'] = Bunch(metadata=metadata, features=features)\n",
    "results = bm(data_dict['improved_EFAAR'], pert_label_col='gene', run_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results_df = get_benchmark_metrics(results)\n",
    "new_results_df['map_version'] = 'JUMP_improved_EFAAR'\n",
    "benchmark_results_df = pd.concat([benchmark_results_df, new_results_df])\n",
    "sns.barplot(data=benchmark_results_df, x='source' ,y='recall', hue='map_version')\n",
    "plt.title('Recall at 5th and 95th Percentiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tvn_univariate_metrics = compute_cosine_sim_metric2(tvn_transformed_well_data)\n",
    "num01genes = len(tvn_univariate_metrics.query(\"avg_cossim_pval<=0.01\"))\n",
    "num05genes = len(tvn_univariate_metrics.query(\"avg_cossim_pval<=0.05\"))\n",
    "print(f\"{num01genes} significant genes at a 0.01 significance threshold\")\n",
    "print(f\"{num05genes} significant genes at a 0.05 significance threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximity Bias in CRISPR Knockout Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Proximity Bias in JUMP Data\n",
    "We create a genome wide heatmap ordered by gene chromosome position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data_path(filename):\n",
    "    return \"data/\"+filename\n",
    "\n",
    "\n",
    "def _chr_to_int(chr):\n",
    "    if chr == \"x\":\n",
    "        return 24\n",
    "    elif chr == \"y\":\n",
    "        return 25\n",
    "    return int(chr)\n",
    "\n",
    "\n",
    "def _chrom_int(chrom):\n",
    "    return chrom.copy().str.split(\"chr\").str[1].str.lower().map(_chr_to_int)\n",
    "\n",
    "VALID_CHROMS = [f\"chr{i}\" for i in range(1, 23)] + [\"chrX\", \"chrY\"]\n",
    "\n",
    "def _load_centromeres() -> pd.DataFrame:\n",
    "    centros = pd.read_csv(_get_data_path(\"centromeres_hg38.tsv\"), sep=\"\\t\", usecols=[\"chrom\", \"chromStart\", \"chromEnd\"])\n",
    "    centros[[\"chromStart\", \"chromEnd\"]] = centros[[\"chromStart\", \"chromEnd\"]].astype(int)\n",
    "    centros = centros.groupby(\"chrom\", as_index=False).agg(\n",
    "        centromere_start=(\"chromStart\", \"min\"),\n",
    "        centromere_end=(\"chromEnd\", \"max\"),\n",
    "    )\n",
    "    return centros\n",
    "\n",
    "\n",
    "def _load_chromosomes(centromeres: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "    chroms = pd.read_csv(_get_data_path(\"hg38_scaffolds.tsv\"), sep=\"\\t\", usecols=[\"chrom\", \"chromStart\", \"chromEnd\"])\n",
    "    chroms[[\"chromStart\", \"chromEnd\"]] = chroms[[\"chromStart\", \"chromEnd\"]].astype(int)\n",
    "    chroms = chroms.loc[chroms.chrom.isin(VALID_CHROMS)].rename(columns={\"chromStart\": \"start\", \"chromEnd\": \"end\"})\n",
    "    chroms[\"chrom_int\"] = _chrom_int(chroms.chrom)\n",
    "\n",
    "    # Merge in centromere data if available\n",
    "    if isinstance(centromeres, pd.DataFrame) and not centromeres.empty:\n",
    "        chroms = chroms.merge(centromeres, on=\"chrom\", how=\"left\")\n",
    "\n",
    "    chroms = chroms.set_index(\"chrom\").sort_values(\"chrom_int\", ascending=True)\n",
    "    return chroms\n",
    "\n",
    "\n",
    "def _load_bands() -> pd.DataFrame:\n",
    "    bands = pd.read_csv(\n",
    "        _get_data_path(\"hg38_cytoband.tsv.gz\"), sep=\"\\t\", usecols=[\"name\", \"#chrom\", \"chromStart\", \"chromEnd\"]\n",
    "    )\n",
    "    bands = bands.rename(columns={\"#chrom\": \"chrom\"})\n",
    "    bands = bands.groupby([\"chrom\", \"name\"], as_index=False).agg(\n",
    "        band_start=(\"chromStart\", \"min\"),\n",
    "        band_end=(\"chromEnd\", \"max\"),\n",
    "        band_chrom_arm=(\"name\", lambda x: x.str[:1].min()),\n",
    "    )\n",
    "    bands[\"chrom_int\"] = _chrom_int(bands.chrom)\n",
    "    return bands\n",
    "\n",
    "\n",
    "def _load_genes(chromosomes: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "    genes = pd.read_csv(\n",
    "        _get_data_path(\"ncbirefseq_hg38.tsv.gz\"), sep=\"\\t\", usecols=[\"name2\", \"chrom\", \"txStart\", \"txEnd\"]\n",
    "    ).rename(columns={\"name2\": \"gene\"})\n",
    "\n",
    "    genes = genes.loc[genes.chrom.isin(VALID_CHROMS)]\n",
    "    genes[\"chrom_int\"] = _chrom_int(genes.chrom)\n",
    "    genes = genes.groupby(\"gene\", as_index=False).agg(\n",
    "        start=(\"txStart\", \"min\"),\n",
    "        end=(\"txEnd\", \"max\"),\n",
    "        chrom_int=(\"chrom_int\", \"min\"),\n",
    "        chrom_count=(\"chrom\", \"nunique\"),\n",
    "        chrom=(\"chrom\", \"first\"),\n",
    "    )\n",
    "\n",
    "    # Filter out (psuedo-)genes of unknown function and genes that show up on multiple chromosomes\n",
    "    genes = genes.loc[~genes.gene.str.contains(\"^LOC*\", regex=True)]\n",
    "    genes = genes.loc[genes.chrom_count == 1].drop(columns=\"chrom_count\").set_index(\"gene\")\n",
    "    genes = genes.sort_values([\"chrom_int\", \"start\", \"end\"], ascending=True)\n",
    "\n",
    "    # Use the middle of the centromere as the way to determine if a gene is on the 0/1 chromosome\n",
    "    if isinstance(chromosomes, pd.DataFrame) and not chromosomes.empty:\n",
    "        chroms_centromere_mid = chromosomes.copy().set_index(\"chrom_int\")\n",
    "        chrom_centromere_mid = (\n",
    "            (chroms_centromere_mid.centromere_start + chroms_centromere_mid.centromere_end) / 2\n",
    "        ).to_dict()\n",
    "        genes[\"chrom_arm_int\"] = genes.apply(lambda x: x.end > chrom_centromere_mid[x.chrom_int], axis=1).astype(int)\n",
    "\n",
    "        # NOTE: Assumes that p is the first chromosome\n",
    "        genes[\"chrom_arm\"] = genes[\"chrom_arm_int\"].apply(lambda x: \"p\" if x == 0 else \"q\")\n",
    "        genes[\"chrom_arm_name\"] = genes[\"chrom\"] + genes[\"chrom_arm\"]\n",
    "    return genes\n",
    "\n",
    "\n",
    "def get_chromosome_info_as_dfs() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get structured information about the chromosomes that genes lie on as three dataframes:\n",
    "        - Genes, including start and end and which chromosome arm they are on\n",
    "        - Chromosomes, including the centromere start and end genomic coordinates\n",
    "        - Cytogenic bands, including the name and start and end genomic\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]\n",
    "        Genes, chromosomes, cytogenic bands\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: refactor into more composable functions\n",
    "    bands = _load_bands()\n",
    "    chroms = _load_chromosomes(centromeres=_load_centromeres())\n",
    "    genes = _load_genes(chromosomes=chroms)\n",
    "\n",
    "    return genes, chroms, bands\n",
    "\n",
    "def get_chromosome_info_as_dicts(\n",
    "    legacy_bands: bool = False,\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert the output of `get_chromosome_info_as_dfs` to dictionary form for compatibility\n",
    "    with legacy notebooks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]\n",
    "        Dict corresponding to genes, chromosomes, and cytogenic bands\n",
    "    \"\"\"\n",
    "    gene_df, chrom_df, band_df = get_chromosome_info_as_dfs()\n",
    "\n",
    "    # Extra composite key for convenience\n",
    "    gene_df[\"arm\"] = gene_df.chrom + gene_df.chrom_arm\n",
    "    gene_dict = gene_df.to_dict(orient=\"index\")\n",
    "\n",
    "    chrom_dict = chrom_df.to_dict(orient=\"index\")\n",
    "\n",
    "    # Extra composite key for convenience\n",
    "    band_df[\"region\"] = band_df.chrom + band_df.name\n",
    "    if legacy_bands:\n",
    "        band_df = band_df[[\"region\", \"chrom\", \"band_start\", \"band_end\"]].set_index(\"region\")\n",
    "        band_dict = {str(k): tuple(v) for k, v in band_df.iterrows()}\n",
    "    else:\n",
    "        band_dict = band_df.to_dict(orient=\"index\")\n",
    "    return gene_dict, chrom_dict, band_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict, chrom_dict, band_dict = get_chromosome_info_as_dicts()\n",
    "genes = list(gene_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2os_exp =  pd.read_csv('data/u2os.csv', index_col='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = aggregated_tvn_data.shape[1]\n",
    "aggregated_tvn_data =aggregated_tvn_data.reset_index()\n",
    "idx = aggregated_tvn_data.query(f\"gene.isin({genes})\").index\n",
    "print(f'Full data has {aggregated_tvn_data.shape[0]} genes, {len(idx)} of which are in hg38 annotations')\n",
    "data_t = aggregated_tvn_data.rename({'Metadata_Symbol': 'gene'}, axis=1)\n",
    "data_t = aggregated_tvn_data.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# Add in chromomsome information\n",
    "data_t['chromosome'] = data_t.gene.apply(lambda x: gene_dict[x]['chrom'] if x in gene_dict else \"no info\" )\n",
    "data_t['chr_idx'] = data_t.gene.apply(lambda x: gene_dict[x]['chrom_int'] if x in gene_dict else \"no info\" )\n",
    "data_t['chromosome_arm'] = data_t.gene.apply(lambda x: gene_dict[x]['arm'] if x in gene_dict else \"no info\" )\n",
    "data_t['gene_bp'] = data_t.gene.apply(lambda x: gene_dict[x][\"start\"] if x in gene_dict else \"no info\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp',] + list(range(0,n_feats))\n",
    "data_t = data_t.loc[:, cols]\n",
    "data_t = data_t.sort_values(['chr_idx', 'gene_bp']).reset_index(drop=True)\n",
    "data_t = data_t.set_index(['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crunch_square_df(\n",
    "    sims: pd.DataFrame,\n",
    "    crunch_factor: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compress `sims` dataframe by `crunch_factor` to make visualizations reasonable. This takes averages of squares of\n",
    "    size `crunch_factor` X `crunch_factor`. Indices are replaced by the first value in the crunch block.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    - sims: pd.DataFrame() with matching row and column indices\n",
    "    - crunch_fctor: int to compress the data by.\n",
    "    \"\"\"\n",
    "\n",
    "    idx = [(i % crunch_factor == 0) for i, x in enumerate(sims.index)]\n",
    "    new_index = sims.index[idx]  # type: ignore\n",
    "    crunched = block_reduce(sims.values, (crunch_factor, crunch_factor), np.mean)\n",
    "\n",
    "    return pd.DataFrame(crunched, index=new_index, columns=new_index)\n",
    "\n",
    "\n",
    "def plot_heatmap(\n",
    "    sims: pd.DataFrame,\n",
    "    f_name: Optional[str] = None,\n",
    "    format: str = \"png\",\n",
    "    crunch_factor: int = 1,\n",
    "    show_chr_lines: bool = True,\n",
    "    show_cent_lines: bool = True,\n",
    "    show_chroms: bool = True,\n",
    "    show_chrom_arms: bool = False,\n",
    "    figsize: tuple = (20, 20),\n",
    "    title: Optional[str] = None,\n",
    "    label_locy: Optional[float] = None,\n",
    "    lab_s: int = 12,\n",
    "    drop_chry: bool = True,\n",
    "    lw: float = 0.5,\n",
    "    lab_rot: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plotting function for heatmaps (full-genome or subsets) can be sorted/clustered or ordered by chromosome\n",
    "\n",
    "    Inputs:\n",
    "    - sims: Square dataframe with matching row and column indices and similarity values. This can be \"split\" along\n",
    "            the diagonal to show different datasets. Index should include `chromosome` and `chromosome_arm` if\n",
    "            ordering by genomic position. Each row/column should represent one gene ordered by genomic position\n",
    "    - f_name: file name\n",
    "    - format: file format for saving a file\n",
    "    - crunch_factor: if > 1 will apply a average smoothing to reduce the size of the output file\n",
    "    - show_chr_lines: whether to show lines at chromosome boundaries\n",
    "    - show_cent_lines: whether to show lines at centromeres\n",
    "    - show_chroms: Whether to label chromosomes on top and right\n",
    "    - show_chrom_arms: whether to label chromosome arms on top and right\n",
    "    - figsize: size of the resulting figure\n",
    "    - title: plot title\n",
    "    - label_locy: location of labels in y\n",
    "    - lab_s: Font size of labels\n",
    "    - drop_chry: Whether to remove Chromosome Y values\n",
    "    - lw: line width\n",
    "    - lab_rot: rotation of labels\n",
    "    \"\"\"\n",
    "    color_norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = mpl.colormaps[\"RdBu_r\"]\n",
    "    # This sets nan values to white\n",
    "    # cmap.set_bad(color='white')\n",
    "\n",
    "    if crunch_factor > 1:\n",
    "        # Downsample the data to make the file size less crazy\n",
    "        # Every `sample_factor`th row/column will be kept\n",
    "        sims = crunch_square_df(sims, crunch_factor=crunch_factor)\n",
    "\n",
    "    image_data = cmap(color_norm(sims.values))\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image_data)\n",
    "\n",
    "    if drop_chry and \"chromosome\" in sims.index.names:\n",
    "        noy_idx = sims.index.get_level_values(\"chromosome\") != \"chrY\"\n",
    "        sims = sims.copy().loc[noy_idx, noy_idx]  # type: ignore\n",
    "\n",
    "    if show_chr_lines or show_chroms or show_cent_lines or show_chrom_arms:\n",
    "        # Get the position of all the chromosomes and centromeres\n",
    "        index_df = sims.index.to_frame(index=False).reset_index().rename({\"index\": \"pos\"}, axis=1)\n",
    "        chr_pos = index_df.groupby(\"chromosome\").pos.max().sort_values()\n",
    "        cent_pos = index_df.groupby(\"chromosome_arm\").pos.max().sort_values()\n",
    "        # Filter to just p-arms\n",
    "        cent_pos_p = cent_pos[[x[-1] == \"p\" for x in cent_pos.index]]\n",
    "        # Get midpoints for annotations\n",
    "        chr_mids = pd.DataFrame(\n",
    "            (np.insert(chr_pos.values[:-1], 0, 0) + chr_pos.values) / 2, index=chr_pos.index  # type: ignore\n",
    "        ).to_dict()[\n",
    "            0  # type: ignore\n",
    "        ]\n",
    "        cent_mids = pd.DataFrame(\n",
    "            (np.insert(cent_pos.values[:-1], 0, 0) + cent_pos.values) / 2, index=cent_pos.index  # type: ignore\n",
    "        ).to_dict()[\n",
    "            0  # type: ignore\n",
    "        ]\n",
    "\n",
    "    # Hide X and Y axes label marks\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_tick_params(labelbottom=False)\n",
    "    ax.yaxis.set_tick_params(labelleft=False)\n",
    "    # Hide X and Y axes tick marks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    xm, xM = ax.get_xlim()\n",
    "    ym, yM = ax.get_ylim()\n",
    "\n",
    "    if show_chr_lines:\n",
    "        for x in chr_pos.values:\n",
    "            plt.plot([x + 0.5, x + 0.5], [ym, yM], color=\"k\", ls=\"-\", lw=lw)\n",
    "            plt.plot([xm, xM], [x + 0.5, x + 0.5], color=\"k\", ls=\"-\", lw=lw)\n",
    "    if show_cent_lines:\n",
    "        for x in cent_pos_p.values:\n",
    "            plt.plot([x + 0.5, x + 0.5], [ym, yM], color=\"k\", ls=\":\", lw=lw)\n",
    "            plt.plot([xm, xM], [x + 0.5, x + 0.5], color=\"k\", ls=\":\", lw=lw)\n",
    "\n",
    "    if show_chroms:\n",
    "        # Label chromosomes on top/right to not clash with coords\n",
    "        ax = plt.gca()\n",
    "        s = sims.shape[0]\n",
    "        for ch in chr_mids:\n",
    "            # Labels across the top\n",
    "            if label_locy is None:\n",
    "                label_locy = -0.008 * s\n",
    "            # Labels on top\n",
    "            ax.text(\n",
    "                chr_mids[ch], label_locy, ch.replace(\"chr\", \"\"), ha=\"center\", va=\"bottom\", rotation=lab_rot, size=lab_s\n",
    "            )\n",
    "            # Labels on the right\n",
    "            ax.text(sims.shape[0] + 0.008 * s, chr_mids[ch], ch.replace(\"chr\", \"\"), ha=\"left\", va=\"center\", size=lab_s)\n",
    "\n",
    "    if show_chrom_arms:\n",
    "        # Label chromosome arms on top/right\n",
    "        ax = plt.gca()\n",
    "        s = sims.shape[0]\n",
    "        for cent in cent_mids:\n",
    "            # Labels across the top\n",
    "            if label_locy is None:\n",
    "                label_locy = -0.008 * s\n",
    "            ax.text(cent_mids[cent], label_locy, cent, ha=\"left\", rotation=lab_rot, size=lab_s)\n",
    "            # Labels on the right\n",
    "            ax.text(sims.shape[0] + 0.001 * s, cent_mids[cent], cent, ha=\"left\", size=lab_s)\n",
    "\n",
    "    plt.title(title, size=\"xx-large\", y=1.1)\n",
    "    plt.gcf().set_facecolor(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(make_pairwise_cos(data_t), f_name=('data/cpg0016_split_prenorm.svg'), \n",
    "             format='svg', crunch_factor=10, title='JUMP Whole Genome Heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Arm Subtraction to Correct for Proximity Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load U2OS expression data\n",
    "u2os_exp = pd.read_csv('data/u2os.csv')\n",
    "u2os_exp = u2os_exp.groupby('gene',as_index=False).zfpkm.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arm_centering_df(\n",
    "    data: pd.DataFrame,\n",
    "    metadata_cols: List[str],\n",
    "    arm_column=\"chromosome_arm\",\n",
    "    subset_query=\"zfpkm <-3\",\n",
    "    min_num_gene=20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a dataframe with the mean feature values for each chromosome arm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame with metadata and features\n",
    "    metadata_cols : List[str]\n",
    "        Metadata columns\n",
    "    arm_column : str, optional\n",
    "        Metadata column with arm identifier, by default \"chromosome_arm\"\n",
    "    subset_query : str, optional\n",
    "        Query to subset genes, by default \"zfpkm <-3\"\n",
    "    min_num_gene : int, optional\n",
    "        Minimum number of genes required. Dataframe returned will only\n",
    "        include arms that meet this threshold, by default 20\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with mean feature values for each chromosome arm\n",
    "    \"\"\"\n",
    "    subset = data.query(subset_query)\n",
    "    if arm_column not in metadata_cols:\n",
    "        metadata_cols = metadata_cols + [arm_column]\n",
    "    features = subset.drop(metadata_cols, axis=\"columns\")\n",
    "    return features.groupby(subset[arm_column]).mean()[\n",
    "        subset.groupby(arm_column)[metadata_cols[0]].size() > min_num_gene\n",
    "    ]\n",
    "\n",
    "\n",
    "def perform_arm_centering(\n",
    "    data: pd.DataFrame,\n",
    "    metadata_cols: List[str],\n",
    "    arm_centering_df: pd.DataFrame,\n",
    "    arm_column: str = \"chromosome_arm\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Apply arm centering to data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Data DataFrame\n",
    "    metadata_cols : List[str]\n",
    "        List of metadata columns\n",
    "    arm_centering_df : pd.DataFrame\n",
    "        Arm centering dataframe\n",
    "    arm_column : str, optional\n",
    "        Column that identifies chromosome arm, by default \"chromosome_arm\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Arm centered data\n",
    "    \"\"\"\n",
    "    metadata = data[metadata_cols]\n",
    "    features = data.drop(metadata_cols, axis=\"columns\")\n",
    "    for chromosome_arm in arm_centering_df.index:\n",
    "        arm_features = features[metadata[arm_column] == chromosome_arm]\n",
    "        arm_features = arm_features - arm_centering_df.loc[chromosome_arm]\n",
    "        features[metadata[arm_column] == chromosome_arm] = arm_features\n",
    "    return metadata.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_t.reset_index()\n",
    "data= data.merge(u2os_exp, how='left', left_on='gene', right_on = 'gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_centering_df = build_arm_centering_df(data, metadata_cols=['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp', 'zfpkm']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_centered_data = perform_arm_centering(data, metadata_cols=['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp', 'zfpkm'], \n",
    "                                          arm_centering_df=arm_centering_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(make_pairwise_cos(arm_centered_data.set_index(['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp', 'zfpkm'])), \n",
    "            f_name=('data/cpg0016_arm_centered.svg'), format='svg', crunch_factor=10, title='JUMP Whole Genome Arm Centered Heatmap')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomputing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = arm_centered_data[['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp', 'zfpkm']]\n",
    "features = arm_centered_data.drop(columns=['gene', 'chromosome', 'chr_idx', 'chromosome_arm', 'gene_bp', 'zfpkm'])\n",
    "data_dict['arm_centered_EFAAR'] = Bunch(metadata=metadata, features=features)\n",
    "arm_centered_results = bm(data_dict['arm_centered_EFAAR'], pert_label_col='gene', run_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_results_df = get_benchmark_metrics(arm_centered_results)\n",
    "arm_results_df['map_version'] = 'JUMP_arm_centered_EFAAR'\n",
    "benchmark_results_df = pd.concat([benchmark_results_df, arm_results_df])\n",
    "sns.barplot(data=benchmark_results_df, x='source' ,y='recall', hue='map_version')\n",
    "plt.title('Recall at 5th and 95th Percentiles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arm Stratified Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efaar_benchmarking.constants import RANDOM_SEED, BENCHMARK_SOURCES, N_NULL_SAMPLES\n",
    "from efaar_benchmarking.utils import (\n",
    "    generate_null_cossims,\n",
    "    generate_query_cossims,\n",
    "    get_benchmark_data,\n",
    "    get_feats_w_indices,\n",
    ")\n",
    "\n",
    "def compute_within_cross_arm_pairwise_metrics(\n",
    "    data: Bunch,\n",
    "    pert_label_col: str = \"gene\",\n",
    "    pct_thresholds: list = [0.05, 0.95],\n",
    ") -> tuple:\n",
    "    \"\"\"Compute known biology benchmarks stratified by whether the pairs of genes\n",
    "    are on the same chromosome arm or not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Bunch\n",
    "        Metadata-features bunch\n",
    "    pert_label_col : str, optional\n",
    "        Column in the metadata that defines the perturbation, by default \"gene\"\n",
    "    pct_thresholds : list, optional\n",
    "        Percentile thresholds for the recall computation, by default [0.05, 0.95]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Results for within-arm and cross-arm pairs, respectively.\n",
    "    \"\"\"\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    within = {}\n",
    "    between = {}\n",
    "    for source in BENCHMARK_SOURCES:\n",
    "        random_seed_pair = np.random.randint(2**32, size=2)\n",
    "        gt_data = get_benchmark_data(source)\n",
    "        gene_dict, _, _ = get_chromosome_info_as_dicts()\n",
    "\n",
    "        feats = get_feats_w_indices(data, pert_label_col)\n",
    "\n",
    "        gt_data[\"entity1_chrom\"] = gt_data.entity1.apply(lambda x: gene_dict[x][\"arm\"] if x in gene_dict else \"no info\")\n",
    "        gt_data[\"entity2_chrom\"] = gt_data.entity2.apply(lambda x: gene_dict[x][\"arm\"] if x in gene_dict else \"no info\")\n",
    "        gt_data = gt_data.query(\"entity1_chrom != 'no info' and entity2_chrom != 'no info'\")\n",
    "        df_gg_null = generate_null_cossims(\n",
    "            feats,\n",
    "            feats,\n",
    "            rseed_entity1=random_seed_pair[0],\n",
    "            rseed_entity2=random_seed_pair[1],\n",
    "            n_entity1=N_NULL_SAMPLES,\n",
    "            n_entity2=N_NULL_SAMPLES,\n",
    "        )\n",
    "\n",
    "        within_gt_subset = gt_data.query(\"entity1_chrom == entity2_chrom\")\n",
    "        between_gt_subset = gt_data.query(\"entity1_chrom != entity2_chrom\")\n",
    "\n",
    "        df_gg_within = generate_query_cossims(feats, feats, within_gt_subset)\n",
    "        df_gg_between = generate_query_cossims(feats, feats, between_gt_subset)\n",
    "\n",
    "        within[source] = _compute_recall(df_gg_null, df_gg_within, pct_thresholds)\n",
    "\n",
    "        between[source] = _compute_recall(df_gg_null, df_gg_between, pct_thresholds)\n",
    "    return within, between\n",
    "\n",
    "def _compute_recall(null_cossims, query_cossims, pct_thresholds) -> dict:\n",
    "    null_sorted = np.sort(null_cossims)\n",
    "    percentiles = np.searchsorted(null_sorted, query_cossims) / len(null_sorted)\n",
    "    return sum((percentiles <= np.min(pct_thresholds)) | (percentiles >= np.max(pct_thresholds))) / len(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_stratified_results = {}\n",
    "for k, v in data_dict.items():\n",
    "    arm_stratified_results[k] = compute_within_cross_arm_pairwise_metrics(v)\n",
    "\n",
    "\n",
    "result_records = []\n",
    "for map_label, v in arm_stratified_results.items():\n",
    "    for name, result in zip((\"within arm\", \"between arms\"), v):\n",
    "        for source, recall in result.items():\n",
    "            result_records.append((map_label, name, source, recall))\n",
    "\n",
    "stratified_results_df = pd.DataFrame.from_records(result_records, columns=[\"Map Name\", \"arms\", \"source\", \"recall\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = stratified_results_df, x = \"arms\", y=\"recall\", hue = \"Map Name\", col = \"source\", kind = \"bar\")\n",
    "plt.title(\"Arm Stratified Benchmarks\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "76625b1555297b59510801a3c242617467e10a4258d8e87339c2a63948eedfe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
