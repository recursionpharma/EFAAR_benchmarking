{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023 Recursion\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.99), (0.02, 0.98), (0.03, 0.97), (0.04, 0.96), (0.05, 0.95), (0.06, 0.94), (0.07, 0.93), (0.08, 0.92), (0.09, 0.91), (0.1, 0.9)]\n"
     ]
    }
   ],
   "source": [
    "from efaar_benchmarking.data_loading import load_cpg16_crispr\n",
    "from efaar_benchmarking.efaar import *\n",
    "from efaar_benchmarking.constants import *\n",
    "from efaar_benchmarking.benchmarking import univariate_consistency_benchmark, multivariate_benchmark\n",
    "from efaar_benchmarking.plotting import plot_recall\n",
    "\n",
    "recall_threshold_pairs = []\n",
    "start = 0.01\n",
    "end = 0.99\n",
    "step = 0.01\n",
    "\n",
    "while start <= .105 and end >= .895:\n",
    "    recall_threshold_pairs.append((round(start,2), round(end,2)))\n",
    "    start += step\n",
    "    end -= step\n",
    "\n",
    "print(recall_threshold_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pc_counts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m2048\u001b[39m]\n\u001b[1;32m      2\u001b[0m all_embeddings_pre_agg \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m features, metadata \u001b[38;5;241m=\u001b[39m \u001b[43mload_cpg16_crispr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# loading may take some time if the files are not cached yet, depending on the speed of your internet connection\u001b[39;00m\n\u001b[1;32m      4\u001b[0m features, metadata \u001b[38;5;241m=\u001b[39m filter_cell_profiler_features(features, metadata)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Raw CP features\u001b[39;00m\n",
      "File \u001b[0;32m~/EFAAR_benchmarking/efaar_benchmarking/data_loading.py:133\u001b[0m, in \u001b[0;36mload_cpg16_crispr\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m    131\u001b[0m             features\u001b[38;5;241m.\u001b[39mappend(future\u001b[38;5;241m.\u001b[39mresult())\n\u001b[1;32m    132\u001b[0m     pd\u001b[38;5;241m.\u001b[39mconcat(features)\u001b[38;5;241m.\u001b[39mto_parquet(features_file_path)\n\u001b[0;32m--> 133\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_file_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    134\u001b[0m metadata_cols \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    135\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mmerge(features, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata_Source\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata_Plate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata_Well\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/eben/lib/python3.10/site-packages/pandas/io/parquet.py:670\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    668\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/eben/lib/python3.10/site-packages/pandas/io/parquet.py:272\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    266\u001b[0m     path,\n\u001b[1;32m    267\u001b[0m     filesystem,\n\u001b[1;32m    268\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    269\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/eben/lib/python3.10/site-packages/pyarrow/parquet/core.py:3003\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2994\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2995\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3000\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   3001\u001b[0m         )\n\u001b[0;32m-> 3003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3009\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/eben/lib/python3.10/site-packages/pyarrow/parquet/core.py:2631\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2624\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2625\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2626\u001b[0m         ]\n\u001b[1;32m   2627\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2628\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2629\u001b[0m         )\n\u001b[0;32m-> 2631\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pc_counts = [128, 256, 512, 1024, 2048]\n",
    "all_embeddings_pre_agg = {}\n",
    "features, metadata = load_cpg16_crispr() # loading may take some time if the files are not cached yet, depending on the speed of your internet connection\n",
    "features, metadata = filter_cell_profiler_features(features, metadata)\n",
    "\n",
    "# Raw CP features\n",
    "all_embeddings_pre_agg[\"CP\"] = features.values\n",
    "all_embeddings_pre_agg[\"CP-CS\"] = centerscale_on_controls(features.values, metadata, pert_col=JUMP_PERT_LABEL_COL, control_key=JUMP_CONTROL_PERT_LABEL)\n",
    "\n",
    "### PCA embeddings with different PC counts and alignment\n",
    "for pcc in pc_counts:\n",
    "    print(pcc)\n",
    "    embeddings = embed_by_pca(features.values, metadata, variance_or_ncomp=pcc, plate_col=JUMP_PLATE_COL)\n",
    "    for k, fn in {f\"CP-PCA{pcc}-CS\": centerscale_on_controls, f\"CP-PCA{pcc}-TVN\": tvn_on_controls}.items():\n",
    "        all_embeddings_pre_agg[k] = fn(embeddings, metadata, pert_col=JUMP_PERT_LABEL_COL, control_key=JUMP_CONTROL_PERT_LABEL)\n",
    "\n",
    "### Aggregate and compute metrics\n",
    "for right_sided in [False]:\n",
    "    all_metrics = {}\n",
    "    for k, embeddings in all_embeddings_pre_agg.items():\n",
    "        # consistency_pvals = univariate_consistency_benchmark(embeddings, metadata, pert_col=JUMP_PERT_LABEL_COL, keys_to_drop=[JUMP_CONTROL_PERT_LABEL, 'no-guide'])\n",
    "        map_data = aggregate(embeddings, metadata, pert_col=JUMP_PERT_LABEL_COL, control_key=JUMP_CONTROL_PERT_LABEL)\n",
    "        metrics = multivariate_benchmark(map_data, recall_thr_pairs=recall_threshold_pairs, pert_col=JUMP_PERT_LABEL_COL, n_null_samples = 10000, n_iterations = 1, right_sided=right_sided)\n",
    "        print(k)\n",
    "        print(metrics.groupby('source')['recall_0.05_0.95'].mean())\n",
    "        all_metrics[f\"JUMP {k}\"] = metrics\n",
    "    plot_recall(all_metrics, right_sided=right_sided, title=\"Right tail only\" if right_sided else \"Both tails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eben",
   "language": "python",
   "name": "eben"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "76625b1555297b59510801a3c242617467e10a4258d8e87339c2a63948eedfe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
