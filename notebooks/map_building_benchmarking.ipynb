{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and variable definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efaar_benchmarking.data_loading import *\n",
    "from efaar_benchmarking.efaar import *\n",
    "from efaar_benchmarking.constants import *\n",
    "from efaar_benchmarking.benchmarking import *\n",
    "from efaar_benchmarking.plotting import *\n",
    "import pickle\n",
    "\n",
    "pc_count = 128\n",
    "save_results = False  # Results already uploaded to the notebooks/data folder in the repo. If True, will replace these files.\n",
    "pert_signal_pval_cutoff = 0.05\n",
    "recall_thr_pairs = [(.05, .95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWPS run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"GWPS\"\n",
    "pert_colname = \"gene\"\n",
    "gem_group_colname = \"gem_group\"\n",
    "control_key = \"non-targeting\"\n",
    "all_controls = [\"non-targeting\"]\n",
    "\n",
    "# Load the perturbation dataset\n",
    "adata_raw = load_gwps(\"raw\")\n",
    "print(\"Perturbation dataset loaded\")\n",
    "metadata = adata_raw.obs\n",
    "\n",
    "# Run EFAAR pipelines\n",
    "all_embeddings_pre_agg = {}\n",
    "print(\"Running for embedding size\", pc_count)\n",
    "all_embeddings_pre_agg[f\"scVI{pc_count}\"] = embed_by_scvi_anndata(adata_raw, batch_col=gem_group_colname, n_latent=pc_count, n_hidden=pc_count*2)\n",
    "print(\"embed_by_scvi_anndata completed\")\n",
    "all_embeddings_pre_agg[f\"scVI{pc_count}-CS\"] = centerscale_on_controls(all_embeddings_pre_agg[f\"scVI{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=gem_group_colname)\n",
    "print(\"centerscale completed\")\n",
    "all_embeddings_pre_agg[f\"scVI{pc_count}-TVN\"] = tvn_on_controls(all_embeddings_pre_agg[f\"scVI{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=gem_group_colname)\n",
    "print(\"tvn completed\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}\"] = embed_by_pca_anndata(adata_raw, gem_group_colname, pc_count)\n",
    "print(\"embed_by_pca_anndata completed\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-CS\"] = centerscale_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=gem_group_colname)\n",
    "print(\"centerscale completed\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-TVN\"] = tvn_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=gem_group_colname)\n",
    "print(\"tvn completed\")\n",
    "\n",
    "# Run biological relationship benchmarks\n",
    "for k, emb in all_embeddings_pre_agg.items():\n",
    "    print(k)\n",
    "    print(\"Aggregating...\")\n",
    "    map_data = aggregate(emb, metadata, pert_col=pert_colname, keys_to_remove=all_controls)\n",
    "    print(\"Computing recall...\")\n",
    "    metrics = known_relationship_benchmark(map_data, recall_thr_pairs=recall_thr_pairs, pert_col=pert_colname)\n",
    "    print(metrics[list(metrics.columns)[::-1]])\n",
    "\n",
    "# Save results\n",
    "if save_results:\n",
    "    with open(f'data/{dataset}_map_cache.pkl', 'wb') as f:\n",
    "        pickle.dump(map_data, f)  # storing the PCA-TVN map data for downstream analysis\n",
    "    with open(f'data/{dataset}_metadata.pkl', 'wb') as f:\n",
    "        pickle.dump(metadata, f)  # storing the metadata for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cpg0016 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cpg0016\"\n",
    "pert_colname = \"Metadata_Symbol\"\n",
    "plate_colname = \"Metadata_Plate\"\n",
    "run_colname = \"Metadata_Batch\"\n",
    "control_key = \"non-targeting\"\n",
    "all_controls = [\"non-targeting\", \"no-guide\"]\n",
    "\n",
    "# Load the perturbation dataset and expression information\n",
    "features, metadata = load_cpg16_crispr()\n",
    "print(\"Perturbation dataset loaded\")\n",
    "features, metadata = filter_cell_profiler_features(features, metadata)\n",
    "\n",
    "expression_data_folder = \"../efaar_benchmarking/expression_data\"\n",
    "expr = pd.read_csv(f\"{expression_data_folder}/U2OS_expression.csv\", index_col=0).groupby(\"gene\").zfpkm.agg(\"median\").reset_index()\n",
    "unexpr_genes = list(expr.loc[expr.zfpkm < -3, \"gene\"])\n",
    "expr_genes = list(expr.loc[expr.zfpkm >= -3, \"gene\"])\n",
    "expr_ind = metadata[pert_colname].isin(expr_genes + [control_key])\n",
    "\n",
    "# Run EFAAR pipelines\n",
    "all_embeddings_pre_agg = {}\n",
    "print(\"Computing PCA embedding for\", pc_count, \"dimensions...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}\"] = embed_by_pca(features.values, metadata, variance_or_ncomp=pc_count, batch_col=plate_colname)\n",
    "print(\"Computing centerscale...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-CS\"] = centerscale_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=run_colname)\n",
    "print(\"Computing TVN...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-TVN\"] = tvn_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=run_colname)\n",
    "\n",
    "# Run perturbation signal benchmarks\n",
    "for k, emb in all_embeddings_pre_agg.items():\n",
    "    cons_res = pert_signal_consistency_benchmark(emb, metadata, pert_col=pert_colname, neg_ctrl_perts=unexpr_genes, keys_to_drop=all_controls)\n",
    "    print(k, round(sum(cons_res.pval <= pert_signal_pval_cutoff) / sum(~pd.isna(cons_res.pval)) * 100, 1))\n",
    "\n",
    "    magn_res = pert_signal_distance_benchmark(emb, metadata, pert_col=pert_colname, neg_ctrl_perts=unexpr_genes, control_key=control_key, keys_to_drop=[x for x in all_controls if x!=control_key])\n",
    "    print(k, round(sum(magn_res.pval <= pert_signal_pval_cutoff) / sum(~pd.isna(magn_res.pval)) * 100, 1))\n",
    "\n",
    "# Run biological relationship benchmarks\n",
    "for k, emb in all_embeddings_pre_agg.items():\n",
    "    print(k)\n",
    "    print(\"Aggregating...\")\n",
    "    map_data = aggregate(emb[expr_ind], metadata[expr_ind], pert_col=pert_colname, keys_to_remove=all_controls)\n",
    "    print(\"Computing recall...\")\n",
    "    metrics = known_relationship_benchmark(map_data, recall_thr_pairs=[(.05, .95)], pert_col=pert_colname)\n",
    "    print(metrics[list(metrics.columns)[::-1]])\n",
    "\n",
    "# Save results\n",
    "if save_results:\n",
    "    with open(f'data/{dataset}_map_cache.pkl', 'wb') as f:\n",
    "        pickle.dump(map_data, f)  # storing the PCA-TVN map data for downstream analysis\n",
    "    with open(f'data/{dataset}_metadata.pkl', 'wb') as f:\n",
    "        pickle.dump(metadata, f)  # storing the metadata for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cpg0021 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cpg0021\"\n",
    "pert_colname = \"Metadata_Foci_Barcode_MatchedTo_GeneCode\"\n",
    "plate_colname = \"Metadata_Plate\"\n",
    "control_key = \"nontargeting\"\n",
    "all_controls = [\"nontargeting\", \"negCtrl\"]\n",
    "\n",
    "# Load the perturbation dataset and expression information\n",
    "features, metadata = load_periscope()\n",
    "print(\"Perturbation dataset loaded\")\n",
    "\n",
    "expression_data_folder = \"../efaar_benchmarking/expression_data\"\n",
    "expr = pd.read_csv(f\"{expression_data_folder}/HeLa_expression.csv\") # note that we assume the HeLa expression data was used for PERISCOPE which is the default option in load_periscope()\n",
    "expr.columns = [\"gene\", \"tpm\"]\n",
    "expr.gene = expr.gene.apply(lambda x: x.split(\" \")[0])\n",
    "unexpr_genes = list(expr.loc[expr.tpm == 0, \"gene\"])\n",
    "expr_genes = list(expr.loc[expr.tpm > 0, \"gene\"])\n",
    "expr_ind = metadata[pert_colname].isin(expr_genes + [control_key])\n",
    "\n",
    "# Run EFAAR pipelines\n",
    "all_embeddings_pre_agg = {}\n",
    "print(\"Computing PCA embedding for\", pc_count, \"dimensions...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}\"] = embed_by_pca(features.values, metadata, variance_or_ncomp=pc_count, batch_col=plate_colname)\n",
    "print(\"Computing centerscale...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-CS\"] = centerscale_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=plate_colname)\n",
    "print(\"Computing TVN...\")\n",
    "all_embeddings_pre_agg[f\"PCA{pc_count}-TVN\"] = tvn_on_controls(all_embeddings_pre_agg[f\"PCA{pc_count}\"], metadata, pert_col=pert_colname, control_key=control_key, batch_col=plate_colname)\n",
    "\n",
    "# Run perturbation signal benchmarks\n",
    "for k, emb in all_embeddings_pre_agg.items():\n",
    "    cons_res = pert_signal_consistency_benchmark(emb, metadata, pert_col=pert_colname, neg_ctrl_perts=unexpr_genes, keys_to_drop=all_controls)\n",
    "    print(k, round(sum(cons_res.pval <= pert_signal_pval_cutoff) / sum(~pd.isna(cons_res.pval)) * 100, 1))\n",
    "\n",
    "    magn_res = pert_signal_distance_benchmark(emb, metadata, pert_col=pert_colname, neg_ctrl_perts=unexpr_genes, control_key=control_key, keys_to_drop=[x for x in all_controls if x!=control_key])\n",
    "    print(k, round(sum(magn_res.pval <= pert_signal_pval_cutoff) / sum(~pd.isna(magn_res.pval)) * 100, 1))\n",
    "\n",
    "# Run biological relationship benchmarks\n",
    "for k, emb in all_embeddings_pre_agg.items():\n",
    "    print(k)\n",
    "    print(\"Aggregating...\")\n",
    "    map_data = aggregate(emb[expr_ind], metadata[expr_ind], pert_col=pert_colname, keys_to_remove=all_controls)\n",
    "    print(\"Computing recall...\")\n",
    "    metrics = known_relationship_benchmark(map_data, recall_thr_pairs=[(.05, .95)], pert_col=pert_colname)\n",
    "    print(metrics[list(metrics.columns)[::-1]])\n",
    "\n",
    "# Save results\n",
    "if save_results:\n",
    "    with open(f'data/{dataset}_map_cache.pkl', 'wb') as f:\n",
    "        pickle.dump(map_data, f)  # storing the PCA-TVN map data for downstream analysis\n",
    "    with open(f'data/{dataset}_metadata.pkl', 'wb') as f:\n",
    "        pickle.dump(metadata, f)  # storing the metadata for downstream analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eben",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
